{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2dc4586-f940-48fa-8190-14f4c73a6eef",
   "metadata": {},
   "source": [
    "Q1. What is the relationship between polynomial functions and kernel functions in machine learning\n",
    "algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd82dae0-def4-4046-a4b1-576baefc31a9",
   "metadata": {},
   "source": [
    "The relationship between polynomial functions and kernel functions lies in the fact that the polynomial kernel is a specific instance of a more general concept of kernels. Kernels, in general, provide a way to measure similarity or distance between data points. Other common kernels include the linear kernel, radial basis function (RBF) or Gaussian kernel, and more.\n",
    "\n",
    "In SVMs, the choice of kernel function is crucial as it determines the form of the decision boundary. Different kernel functions capture different types of relationships in the data. Polynomial kernels are useful when the decision boundary is expected to have a polynomial shape."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53db242a-9b41-433b-a61e-6ba83783ec2c",
   "metadata": {},
   "source": [
    "Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9bfc73-c848-4934-9361-58be57551100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # Use only two features for visualization\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into a training set and a testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an SVM with a polynomial kernel\n",
    "# You can adjust the degree of the polynomial by changing the 'degree' parameter\n",
    "# C is the regularization parameter\n",
    "poly_svm = SVC(kernel='poly', degree=3, C=1)\n",
    "poly_svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = poly_svm.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Plot decision boundary\n",
    "def plot_decision_boundary(X, y, model, title):\n",
    "    h = .02  # Step size in the mesh\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm, edgecolors='k', marker='o')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "    plt.show()\n",
    "\n",
    "# Plot decision boundary for the polynomial SVM\n",
    "plot_decision_boundary(X, y, poly_svm, 'SVM with Polynomial Kernel')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a9a3d7-fe26-4907-b8c4-003ec1b8f827",
   "metadata": {},
   "source": [
    "Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb63bbf-0391-4e18-b026-eba7da0f672c",
   "metadata": {},
   "source": [
    "In Support Vector Regression (SVR), the parameter epsilon (\n",
    "ε) is a part of the \n",
    "ε-insensitive tube, which defines a region within which errors are tolerated. This tube plays a crucial role in determining the number of support vectors and the flexibility of the SVR model.\n",
    "\n",
    "When you increase the value of epsilon:\n",
    "\n",
    "Wider \n",
    "ε-Insensitive Tube:\n",
    "\n",
    "A larger epsilon results in a wider \n",
    "ε-insensitive tube around the regression line.\n",
    "Data points within this tube are not considered errors, and their associated loss is zero.\n",
    "This increased tolerance allows for a larger range of errors that are acceptable.\n",
    "More Support Vectors:\n",
    "\n",
    "Support vectors are the data points that lie on the boundary of the \n",
    "ε-insensitive tube or have non-zero coefficients in the SVR model.\n",
    "As epsilon increases, more data points may fall within the wider tube without contributing to the loss.\n",
    "Consequently, the number of support vectors tends to increase because more data points are within the acceptable error range.\n",
    "Increased Model Flexibility:\n",
    "\n",
    "A larger \n",
    "ε provides greater flexibility to the model, allowing it to fit the training data more loosely.\n",
    "The SVR model becomes more tolerant of errors, and the optimization process may prioritize a wider tube over minimizing the number of support vectors.\n",
    "Potential Overfitting:\n",
    "\n",
    "While a larger \n",
    "ε can improve the fit to the training data, it may also increase the risk of overfitting, especially if the training data has noise or outliers.\n",
    "The model might capture more details in the training data that do not generalize well to new, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8236f9-83b7-4ffa-b6af-7016ca0696dd",
   "metadata": {},
   "source": [
    "Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter\n",
    "affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works\n",
    "and provide examples of when you might want to increase or decrease its value?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4aa1dd6-ff61-4032-b9e0-cb7dfce4a663",
   "metadata": {},
   "source": [
    "Support Vector Regression (SVR) involves several parameters that can significantly impact the performance of the model. Let's discuss the key parameters - kernel function, C parameter, epsilon parameter (\n",
    "\n",
    "ε), and gamma parameter (\n",
    "γ) - and understand how each parameter works, along with considerations for adjusting their values:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32378b34-58b4-4eec-9dd5-470901aba15c",
   "metadata": {},
   "source": [
    "Q5. Assignment:\n",
    "L Import the necessary libraries and load the dataseg\n",
    "L Split the dataset into training and testing setZ\n",
    "L Preprocess the data using any technique of your choice (e.g. scaling, normaliMationK\n",
    "L Create an instance of the SVC classifier and train it on the training datW\n",
    "L hse the trained classifier to predict the labels of the testing datW\n",
    "L Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy,\n",
    "precision, recall, F1-scoreK\n",
    "L Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomiMedSearchCV to\n",
    "improve its performanc_\n",
    "L Train the tuned classifier on the entire dataseg\n",
    "L Save the trained classifier to a file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570ac433-2087-46ff-b5d0-8594a9f42e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data using standard scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create an instance of the SVC classifier and train it on the training data\n",
    "svc_classifier = SVC(kernel='rbf', C=1, gamma='scale')  # You can adjust kernel, C, and gamma\n",
    "svc_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Use the trained classifier to predict the labels of the testing data\n",
    "y_pred = svc_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the performance of the classifier using accuracy and classification report\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\\n\", classification_rep)\n",
    "\n",
    "# Tune the hyperparameters using GridSearchCV\n",
    "param_grid = {'C': [0.1, 1, 10], 'gamma': ['scale', 'auto'], 'kernel': ['linear', 'rbf']}\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters from the grid search\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Train the tuned classifier on the entire dataset\n",
    "tuned_svc_classifier = SVC(**best_params)\n",
    "tuned_svc_classifier.fit(X_scaled, y)\n",
    "\n",
    "# Save the trained classifier to a file for future use\n",
    "joblib.dump(tuned_svc_classifier, 'tuned_svc_classifier.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8b6fd6-3f7f-4bf3-8e12-4c168d55c9cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fa34b6-33c0-44d3-b339-1e6a3cf0a009",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
