{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "711af86d-8349-43d1-b283-b4e17c46811e",
   "metadata": {},
   "source": [
    "Q1. Import the dataset and examine the variables. Use descriptive statistics and visualizations to\n",
    "understand the distribution and relationships between the variables. you  have a diabetes data \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af37a25e-ed42-4870-865c-39998d606c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the diabetes dataset (replace 'your_dataset.csv' with the actual file path)\n",
    "diabetes_data = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(diabetes_data.info())\n",
    "\n",
    "# Display descriptive statistics\n",
    "print(diabetes_data.describe())\n",
    "\n",
    "# Visualize the distribution of variables using histograms\n",
    "diabetes_data.hist(figsize=(10, 10))\n",
    "plt.show()\n",
    "\n",
    "# Visualize relationships between variables using pair plots\n",
    "sns.pairplot(diabetes_data)\n",
    "plt.show()\n",
    "\n",
    "# Visualize correlations between variables using a heatmap\n",
    "correlation_matrix = diabetes_data.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527d6529-bcb4-4c0d-a503-99793322693d",
   "metadata": {},
   "source": [
    "Q2. Preprocess the data by cleaning missing values, removing outliers, and transforming categorical\n",
    "variables into dummy variables if necessary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb5734b-f604-4804-b446-b6db40f2c620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the diabetes dataset (replace 'your_dataset.csv' with the actual file path)\n",
    "diabetes_data = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Display missing values\n",
    "print(\"Missing values before preprocessing:\")\n",
    "print(diabetes_data.isnull().sum())\n",
    "\n",
    "# Handle missing values (replace NaN with mean, median, or other strategies)\n",
    "diabetes_data.fillna(diabetes_data.mean(), inplace=True)\n",
    "\n",
    "# Display outliers using box plots (replace 'feature_name' with the actual column name)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=diabetes_data['feature_name'])\n",
    "plt.title('Box Plot for Outliers')\n",
    "plt.show()\n",
    "\n",
    "# Remove outliers using the IQR (Interquartile Range) method\n",
    "Q1 = diabetes_data['feature_name'].quantile(0.25)\n",
    "Q3 = diabetes_data['feature_name'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "diabetes_data = diabetes_data[(diabetes_data['feature_name'] >= Q1 - 1.5 * IQR) & (diabetes_data['feature_name'] <= Q3 + 1.5 * IQR)]\n",
    "\n",
    "# Display missing values after preprocessing\n",
    "print(\"Missing values after preprocessing:\")\n",
    "print(diabetes_data.isnull().sum())\n",
    "\n",
    "# Transform categorical variables into dummy variables (if necessary)\n",
    "# For example, if 'gender' is a categorical variable\n",
    "diabetes_data = pd.get_dummies(diabetes_data, columns=['gender'], drop_first=True)\n",
    "\n",
    "# Display the preprocessed dataset\n",
    "print(\"Preprocessed dataset:\")\n",
    "print(diabetes_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9102018-73f7-467f-8f0e-46c8af4c3eec",
   "metadata": {},
   "source": [
    "Q3. Split the dataset into a training set and a test set. Use a random seed to ensure reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68024034-98d5-4533-a165-490ec4a504bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'diabetes_data' is your preprocessed DataFrame with features and target variable\n",
    "# Replace 'target_column' with the actual column name of your target variable\n",
    "X = diabetes_data.drop('target_column', axis=1)\n",
    "y = diabetes_data['target_column']\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "random_seed = 42\n",
    "\n",
    "# Split the dataset into training and test sets (typically, 80% training and 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)\n",
    "\n",
    "# Display the shapes of the training and test sets\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdc6247-d704-4b51-8d5a-83893235c584",
   "metadata": {},
   "source": [
    "Q4. Use a decision tree algorithm, such as ID3 or C4.5, to train a decision tree model on the training set. Use\n",
    "cross-validation to optimize the hyperparameters and avoid overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e768bd7d-0df8-40a3-9985-5c7e052e9105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Create a decision tree classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Define the hyperparameter grid for optimization\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV for hyperparameter optimization and cross-validation\n",
    "grid_search = GridSearchCV(dt_classifier, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Train a decision tree model with the best hyperparameters on the entire training set\n",
    "best_dt_model = DecisionTreeClassifier(**best_params, random_state=42)\n",
    "best_dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_dt_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Display the results\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Accuracy on Test Set:\", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_rep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08038d62-8573-4938-9e95-7836295153c8",
   "metadata": {},
   "source": [
    "Q5. Evaluate the performance of the decision tree model on the test set using metrics such as accuracy,\n",
    "precision, recall, and F1 score. Use confusion matrices and ROC curves to visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfefb065-f8dd-4252-a132-11500b59844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_dt_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Display metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Create a confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Calculate and plot the ROC curve\n",
    "y_proba = best_dt_model.predict_proba(X_test)[:, 1]  # Probability of positive class\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "plt.title('ROC Curve')\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cc9c86-4655-4403-8387-31a58bb327bc",
   "metadata": {},
   "source": [
    "Q6. Interpret the decision tree by examining the splits, branches, and leaves. Identify the most important\n",
    "variables and their thresholds. Use domain knowledge and common sense to explain the patterns and\n",
    "trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e826f9e-1f81-4a6b-bb4d-8cfadc7df02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# Visualize the decision tree\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(best_dt_model, feature_names=X.columns, class_names=[\"Negative\", \"Positive\"], filled=True, rounded=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812e6f6e-9258-40e8-81e3-e62683828688",
   "metadata": {},
   "source": [
    "Q7. Validate the decision tree model by applying it to new data or testing its robustness to changes in the\n",
    "dataset or the environment. Use sensitivity analysis and scenario testing to explore the uncertainty and\n",
    "risks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbefe141-885a-4ef6-b0ad-6be0be014ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'new_data' is your new dataset\n",
    "new_data = pd.read_csv('new_data.csv')  # Replace with the actual file path\n",
    "X_new = new_data.drop('target_column', axis=1)\n",
    "y_new = new_data['target_column']\n",
    "\n",
    "# Predict on new data\n",
    "y_pred_new = best_dt_model.predict(X_new)\n",
    "\n",
    "# Evaluate the model on new data\n",
    "accuracy_new = accuracy_score(y_new, y_pred_new)\n",
    "precision_new = precision_score(y_new, y_pred_new)\n",
    "recall_new = recall_score(y_new, y_pred_new)\n",
    "f1_new = f1_score(y_new, y_pred_new)\n",
    "\n",
    "# Display metrics for new data\n",
    "print(\"Validation on New Data:\")\n",
    "print(\"Accuracy:\", accuracy_new)\n",
    "print(\"Precision:\", precision_new)\n",
    "print(\"Recall:\", recall_new)\n",
    "print(\"F1 Score:\", f1_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7ed3ec-abd3-4d34-9223-e16f370e4e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example sensitivity analysis for a specific feature ('feature_name')\n",
    "feature_to_test = 'feature_name'\n",
    "original_values = X_test[feature_to_test].copy()\n",
    "\n",
    "# Perturb the feature and observe the impact on predictions\n",
    "for perturbation in [0.1, 0.5, 1.0]:\n",
    "    X_test[feature_to_test] = original_values * perturbation\n",
    "    y_pred_perturbed = best_dt_model.predict(X_test)\n",
    "    accuracy_perturbed = accuracy_score(y_test, y_pred_perturbed)\n",
    "    print(f\"Perturbation factor: {perturbation}, Accuracy: {accuracy_perturbed}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
