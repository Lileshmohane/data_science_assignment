{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "148e92e7-1543-4892-9888-771b454e9fd5",
   "metadata": {},
   "source": [
    "Q1. What is Bayes' theorem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89860cb4-7a14-4598-9b2e-306ef806052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Bayes' theorem, named after the Reverend Thomas Bayes, is a fundamental concept in probability theory and statistics. It describes the probability of an event based on prior knowledge or information about related events\n",
    "P(A∣B)= P(B∣A)×P(A)/P(B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab07926f-f4c5-4aee-b5a0-ed9eadeae08b",
   "metadata": {},
   "source": [
    "Q2. What is the formula for Bayes' theorem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388428a4-2a6c-47f7-9b1b-127d36896569",
   "metadata": {},
   "outputs": [],
   "source": [
    "P(A∣B)= P(B∣A)×P(A)/P(B)\n",
    "P(A∣B) is the probability of event A occurring given that event B has occurred (the posterior probability).\n",
    "P(B∣A) is the probability of event B occurring given that event A has occurred (the likelihood).\n",
    "P(A) is the probability of event A occurring (the prior probability).\n",
    "P(B) is the probability of event B occurring.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06187e0-b7d5-4606-ba73-5ed82ffb3dd0",
   "metadata": {},
   "source": [
    "Q3. How is Bayes' theorem used in practice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69679441-6ad5-4714-a132-918093a3459a",
   "metadata": {},
   "source": [
    "Medical Diagnosis: Bayes' theorem is frequently used in medical diagnosis, where it helps clinicians assess the probability of a patient having a particular disease based on observed symptoms and medical test results. By incorporating prior knowledge about the prevalence of the disease and the accuracy of the tests, Bayes' theorem allows for more accurate diagnosis.\n",
    "\n",
    "Spam Filtering: In email spam filtering, Bayes' theorem is used to classify incoming emails as either spam or legitimate based on the presence of certain words or patterns in the email content. By calculating the probability of an email being spam given the observed words (likelihood) and considering the overall prevalence of spam emails (prior probability), spam filters can effectively separate unwanted emails from legitimate ones.\n",
    "\n",
    "Weather Forecasting: Bayes' theorem can be applied in weather forecasting to update predictions based on new data or observations. Meteorologists use prior weather data and knowledge about atmospheric conditions to make initial predictions, and then they update these predictions using real-time data from weather stations and satellites, applying Bayes' theorem to refine the forecasts.\n",
    "\n",
    "Document Classification: In natural language processing and text mining, Bayes' theorem is used for document classification tasks such as sentiment analysis, topic modeling, and language detection. By calculating the probability of a document belonging to a particular category given its features (such as words or phrases), Bayes' theorem enables accurate classification of documents into predefined categories.\n",
    "\n",
    "Fault Diagnosis in Engineering: Bayes' theorem is applied in fault diagnosis and condition monitoring of mechanical systems, electrical circuits, and other engineering systems. By considering prior knowledge about the behavior of the system and observed sensor data, engineers can estimate the probability of different fault scenarios and take appropriate maintenance or corrective actions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5e9ede-7c29-4746-9f1f-9786185760fd",
   "metadata": {},
   "source": [
    "Q4. What is the relationship between Bayes' theorem and conditional probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1233d2-4241-4f82-a570-a24271b2e12d",
   "metadata": {},
   "source": [
    "\n",
    "Bayes' theorem is closely related to conditional probability, as it provides a mathematical framework for calculating conditional probabilities in certain situations. Conditional probability is the probability of an event occurring given that another event has already occurred."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb1c4ce-1d08-4eb9-98fb-606d4e794f4d",
   "metadata": {},
   "source": [
    "Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b7eba0-3f50-44c6-b3d3-69280613be32",
   "metadata": {},
   "source": [
    "Gaussian Naive Bayes:\n",
    "\n",
    "Assumption: Assumes that continuous features follow a Gaussian (normal) distribution.\n",
    "Use Cases: Suitable for classification tasks with continuous or real-valued features that can be reasonably modeled as Gaussian distributions, such as sensor data, physiological measurements, or financial data.\n",
    "Multinomial Naive Bayes:\n",
    "\n",
    "Assumption: Assumes that features follow a multinomial distribution, typically used for discrete features representing counts or frequencies.\n",
    "Use Cases: Commonly used in text classification tasks where features represent word counts or frequencies (e.g., document classification, spam filtering), as well as other categorical data with multiple classes.\n",
    "Bernoulli Naive Bayes:\n",
    "\n",
    "Assumption: Assumes that features are binary (i.e., presence or absence of a feature).\n",
    "Use Cases: Suitable for binary feature data, such as document classification tasks where features represent the presence or absence of certain words (e.g., bag-of-words representation), or other binary data like presence/absence of certain attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6c47ed-eba0-4a8c-9b22-380e341b983b",
   "metadata": {},
   "source": [
    "Q6. Assignment:\n",
    "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive\n",
    "Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of\n",
    "each feature value for each class:\n",
    "Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "A 3 3 4 4 3 3 3\n",
    "B 2 2 1 2 2 2 3\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
    "to belong to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3f4d54-1de4-41e6-971e-e74f97af61ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "P(A∣X \n",
    "1=3,X \n",
    "2\n",
    "​\n",
    " =4)>P(B∣X \n",
    "1\n",
    "​\n",
    " =3,X \n",
    "2\n",
    "​\n",
    " =4), so the Naive Bayes classifier would predict that the new instance belongs to class A."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
