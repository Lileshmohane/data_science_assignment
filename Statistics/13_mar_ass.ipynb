{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20687f6b-53c5-4b9c-b2bd-c82b95a2be8d",
   "metadata": {},
   "source": [
    "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
    "the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119c88a5-c4f8-4882-a22b-9bc03e9fd838",
   "metadata": {},
   "source": [
    "Analysis of Variance (ANOVA) is a statistical technique used to compare means among three or more groups or treatments. To use ANOVA effectively and trust the validity of its results, several assumptions must be met. Violations of these assumptions can affect the validity of the ANOVA results. Here are the key assumptions of ANOVA and examples of violations:\n",
    "\n",
    "Independence Assumption:\n",
    "\n",
    "Assumption: The observations in each group are independent of each other.\n",
    "Violation Example: In a study comparing the exam scores of students from different schools, if students within the same school collaborate or share information, the independence assumption is violated.\n",
    "Normality Assumption:\n",
    "\n",
    "Assumption: The residuals (the differences between observed values and predicted values) for each group should be normally distributed.\n",
    "Violation Example: If the residuals are skewed or have a non-normal distribution for one or more groups, this assumption is violated. For example, if the residuals for a group have a significant positive skew, this could indicate a violation.\n",
    "Homogeneity of Variance Assumption (Homoscedasticity):\n",
    "\n",
    "Assumption: The variances of the residuals for each group should be approximately equal.\n",
    "Violation Example: If the variance of residuals is not constant across groups (i.e., one group has much larger variance than others), it violates the homogeneity of variance assumption. This could be detected by a Levene's test or visual inspection of residual plots.\n",
    "Random Sampling Assumption:\n",
    "\n",
    "Assumption: The data should be collected through random sampling methods to ensure the results can be generalized to a larger population.\n",
    "Violation Example: If the data is collected using a non-random or biased sampling method, the results may not be representative of the population, and the generalizability of the findings could be compromised."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59929dc1-9b82-498a-a8bb-8007da02b9f0",
   "metadata": {},
   "source": [
    "Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfea8fd-0672-4a59-8d96-27430117c232",
   "metadata": {},
   "source": [
    "Analysis of Variance (ANOVA) is a statistical technique used to compare means among three or more groups or treatments. There are three main types of ANOVA, each used in different situations:\n",
    "\n",
    "One-Way ANOVA:\n",
    "\n",
    "Situation: One-Way ANOVA is used when you have one categorical independent variable (also known as a factor) with three or more levels or groups, and you want to determine if there are any statistically significant differences in the means of a continuous dependent variable among these groups.\n",
    "Example: Suppose you want to compare the mean test scores of students who attended three different schools (School A, School B, and School C) to determine if there are significant differences in performance across the schools. One-Way ANOVA would be appropriate in this case.\n",
    "Two-Way ANOVA:\n",
    "\n",
    "Situation: Two-Way ANOVA is used when you have two categorical independent variables (factors), and you want to examine the effect of each factor individually as well as their interaction on a continuous dependent variable.\n",
    "Example: Consider a study where you want to investigate the impact of both gender (Male vs. Female) and treatment type (Treatment A vs. Treatment B) on patient recovery time. Two-Way ANOVA allows you to assess the main effects of gender and treatment as well as whether there is an interaction effect between the two.\n",
    "Repeated Measures ANOVA:\n",
    "\n",
    "Situation: Repeated Measures ANOVA is used when you have a within-subjects design, meaning that the same subjects are measured under multiple conditions or at different time points. It's used to assess changes within the same subjects over time or across conditions.\n",
    "Example: Suppose you are conducting a study to evaluate the effect of a new drug on blood pressure. You measure the blood pressure of the same group of participants at baseline, after one week of treatment, after two weeks of treatment, and after three weeks of treatment. Repeated Measures ANOVA would help you determine if there are significant changes in blood pressure over time as a result of the treatment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2d960b-cbe1-4e24-8f40-dc77d0172cbb",
   "metadata": {},
   "source": [
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18ff785-8212-4258-a849-b1132ccc5848",
   "metadata": {},
   "source": [
    "The partitioning of variance in Analysis of Variance (ANOVA) refers to the process of decomposing the total variability observed in a dataset into different components or sources of variation. Understanding this concept is crucial in ANOVA because it allows researchers to determine the relative importance of various factors and sources of variation in explaining the variability in the dependent variable. This partitioning is fundamental for drawing valid conclusions and making inferences about the groups or treatments being compared.\n",
    "Total Variance (Total Sum of Squares, SST):\n",
    "\n",
    "Total variance represents the overall variability in the dependent variable. It is calculated as the sum of the squared differences between each individual data point and the overall mean of all the data points.\n",
    "SST = Σ(yi - ȳ)²\n",
    "Between-Group Variance (Between-Group Sum of Squares, SSB):\n",
    "\n",
    "Between-group variance represents the variability in the dependent variable that can be attributed to differences between the groups or treatments being compared. It is calculated as the sum of the squared differences between each group's mean and the overall mean\n",
    "SSB = Σ(ni * (ȳi - ȳ)²)\n",
    "Within-Group Variance (Within-Group Sum of Squares, SSW):\n",
    "\n",
    "Within-group variance represents the variability in the dependent variable that is not explained by differences between groups. It is calculated as the sum of the squared differences between each data point and its group's mean\n",
    "SSW = Σ(yi - ȳi)²"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9287a9d-d71f-4e53-986e-eea25c0ef511",
   "metadata": {},
   "source": [
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b256dd8f-c4b7-4be5-bee5-82646a5cf700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST (Total Sum of Squares): 477.33333333333326\n",
      "SSE (Explained Sum of Squares): 397.73333333333346\n",
      "SSR (Residual Sum of Squares): 79.6\n",
      "F-statistic: 29.979899497487448\n",
      "P-value: 2.150541495837821e-05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data for each group (replace with your data)\n",
    "group1 = np.array([28, 32, 30, 25, 29])\n",
    "group2 = np.array([35, 36, 33, 30, 31])\n",
    "group3 = np.array([40, 45, 42, 38, 41])\n",
    "\n",
    "# Combine all data into a single array\n",
    "all_data = np.concatenate([group1, group2, group3])\n",
    "\n",
    "# Calculate the overall mean (ȳ)\n",
    "overall_mean = np.mean(all_data)\n",
    "\n",
    "# Calculate the Total Sum of Squares (SST)\n",
    "sst = np.sum((all_data - overall_mean) ** 2)\n",
    "\n",
    "# Calculate the group means (ȳi) for each group\n",
    "group1_mean = np.mean(group1)\n",
    "group2_mean = np.mean(group2)\n",
    "group3_mean = np.mean(group3)\n",
    "\n",
    "# Calculate the Explained Sum of Squares (SSE)\n",
    "sse = len(group1) * (group1_mean - overall_mean) ** 2\n",
    "sse += len(group2) * (group2_mean - overall_mean) ** 2\n",
    "sse += len(group3) * (group3_mean - overall_mean) ** 2\n",
    "\n",
    "# Calculate the Residual Sum of Squares (SSR)\n",
    "ssr = np.sum((group1 - group1_mean) ** 2)\n",
    "ssr += np.sum((group2 - group2_mean) ** 2)\n",
    "ssr += np.sum((group3 - group3_mean) ** 2)\n",
    "\n",
    "# Calculate the degrees of freedom (DF) for SST, SSE, and SSR\n",
    "total_df = len(all_data) - 1\n",
    "explained_df = len([group1, group2, group3]) - 1\n",
    "residual_df = len(all_data) - len([group1, group2, group3])\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic = (sse / explained_df) / (ssr / residual_df)\n",
    "p_value = 1 - stats.f.cdf(f_statistic, explained_df, residual_df)\n",
    "\n",
    "print(f\"SST (Total Sum of Squares): {sst}\")\n",
    "print(f\"SSE (Explained Sum of Squares): {sse}\")\n",
    "print(f\"SSR (Residual Sum of Squares): {ssr}\")\n",
    "print(f\"F-statistic: {f_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6d82e9-9f2c-44aa-bd9e-66e4400f708c",
   "metadata": {},
   "source": [
    "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5481a27b-d39e-4304-98fe-47f70c87138d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "# Sample data for the two factors and the dependent variable\n",
    "data = pd.DataFrame({\n",
    "    'Factor_A': ['A1', 'A1', 'A2', 'A2', 'A3', 'A3', 'A4', 'A4'],\n",
    "    'Factor_B': ['B1', 'B2', 'B1', 'B2', 'B1', 'B2', 'B1', 'B2'],\n",
    "    'Dependent_Variable': [10, 12, 14, 15, 20, 21, 18, 19]\n",
    "})\n",
    "\n",
    "# Perform two-way ANOVA using statsmodels\n",
    "formula = 'Dependent_Variable ~ C(Factor_A) + C(Factor_B) + C(Factor_A):C(Factor_B)'\n",
    "model = ols(formula, data=data).fit()\n",
    "anova_table = anova_lm(model, typ=2)\n",
    "\n",
    "# Extract the main effects and interaction effect\n",
    "main_effect_A = anova_table['sum_sq']['C(Factor_A)'] / anova_table['df']['C(Factor_A)']\n",
    "main_effect_B = anova_table['sum_sq']['C(Factor_B)'] / anova_table['df']['C(Factor_B)']\n",
    "interaction_effect = anova_table['sum_sq']['C(Factor_A):C(Factor_B)'] / anova_table['df']['C(Factor_A):C(Factor_B)']\n",
    "\n",
    "# Print the results\n",
    "print(\"Main Effect of Factor A:\", main_effect_A)\n",
    "print(\"Main Effect of Factor B:\", main_effect_B)\n",
    "print(\"Interaction Effect:\", interaction_effect)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e408f5b-f39b-48d3-895e-148ae8bf157d",
   "metadata": {},
   "source": [
    "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "What can you conclude about the differences between the groups, and how would you interpret these\n",
    "results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1dd491-9e91-4804-98b2-bf07deac4374",
   "metadata": {},
   "source": [
    "In a one-way ANOVA, the F-statistic is used to test whether there are statistically significant differences in the means of three or more groups. The associated p-value helps you determine the significance of these differences. In your case, you obtained an F-statistic of 5.23 and a p-value of 0.02. Here's how you can interpret these results:\n",
    "\n",
    "F-Statistic:\n",
    "\n",
    "The F-statistic is a measure of the ratio of the variation between group means to the variation within groups. It tells you whether the observed differences in means between groups are statistically significant.\n",
    "P-Value:\n",
    "\n",
    "The p-value associated with the F-statistic indicates the probability of obtaining an F-statistic as extreme as the one observed (or more extreme) under the null hypothesis that there are no significant differences between the group means.\n",
    "Interpretation:\n",
    "\n",
    "Since the p-value (0.02) is less than the commonly chosen significance level (e.g., 0.05), you would typically reject the null hypothesis. This means that there is evidence to suggest that at least one group mean is different from the others.\n",
    "\n",
    "However, a low p-value alone does not tell you which specific groups are different from each other. To determine which groups are different, you would need to perform post hoc tests (e.g., Tukey's HSD, Bonferroni correction, etc.) to make pairwise comparisons between groups.\n",
    "\n",
    "The F-statistic (5.23) itself indicates that there is some degree of variability between the group means relative to the variability within the groups. However, it doesn't provide information about the size of the effect or which groups contribute the most to the observed differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69364c3-692c-4e21-9e02-e77dee3a1ac6",
   "metadata": {},
   "source": [
    "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a78cdd-0e18-4953-a54d-a69fc23675a4",
   "metadata": {},
   "source": [
    "Handling missing data in a repeated measures ANOVA is crucial to ensure the validity of your analysis and the accuracy of the results. There are several methods for handling missing data, and the choice of method can have consequences for your analysis. Here are some common approaches and their potential consequences:\n",
    "\n",
    "Listwise Deletion (Complete Case Analysis):\n",
    "\n",
    "Method: This approach involves removing cases (participants) with missing data from the analysis. Only cases with complete data across all time points are included.\n",
    "Consequences:\n",
    "Pros:\n",
    "Simple and easy to implement.\n",
    "Preserves the sample size for analysis.\n",
    "Cons:\n",
    "May lead to a loss of valuable information if a large number of cases have missing data.\n",
    "Can introduce bias if the missing data are not missing completely at random (MCAR) but instead have a systematic pattern (missing at random, or MAR).\n",
    "Mean Imputation:\n",
    "\n",
    "Method: Missing values are replaced with the mean of the observed values for the variable.\n",
    "Consequences:\n",
    "Pros:\n",
    "Maintains the sample size for analysis.\n",
    "Cons:\n",
    "Can introduce bias by assuming that missing values have the same mean as observed values.\n",
    "Reduces variability in the data, potentially leading to underestimated standard errors and inflated statistical significance.\n",
    "Interpolation or Linear Imputation:\n",
    "\n",
    "Method: Missing values are estimated based on linear interpolation or regression techniques using the observed data.\n",
    "Consequences:\n",
    "Pros:\n",
    "More sophisticated than mean imputation and can provide better estimates.\n",
    "Cons:\n",
    "Requires making assumptions about the underlying relationships in the data, which may not always be valid.\n",
    "May not be appropriate for all types of data or missing data patterns.\n",
    "Multiple Imputation:\n",
    "\n",
    "Method: Multiple imputation generates multiple sets of imputed values to account for uncertainty in missing data. These sets are analyzed separately, and the results are combined to provide more accurate estimates.\n",
    "Consequences:\n",
    "Pros:\n",
    "Provides more accurate and unbiased estimates compared to single imputation methods.\n",
    "Accounts for the uncertainty associated with missing data.\n",
    "Cons:\n",
    "Can be computationally intensive and may require specialized software.\n",
    "Requires making assumptions about the missing data mechanism and distribution.\n",
    "Model-Based Imputation:\n",
    "\n",
    "Method: Missing data are imputed using statistical models specific to the data and research question.\n",
    "Consequences:\n",
    "Pros:\n",
    "Can provide highly accurate imputations when done correctly.\n",
    "Allows for flexibility in modeling the missing data mechanism.\n",
    "Cons:\n",
    "Can be complex and may require expertise in statistical modeling.\n",
    "Requires careful consideration of model assumptions and potential for model misspecification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633df5fa-b365-406d-b7ed-f0d9e8ae51fd",
   "metadata": {},
   "source": [
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
    "an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f90380d-070d-4255-abec-20c778d7ef90",
   "metadata": {},
   "source": [
    "Post-hoc tests are statistical tests that are conducted after an Analysis of Variance (ANOVA) to make pairwise comparisons between groups when the ANOVA reveals a significant overall difference. They help identify which specific groups are different from each other. Several common post-hoc tests are available, and the choice of which one to use depends on the design of your study and the assumptions you are willing to make. Here are some common post-hoc tests and when to use each one:\n",
    "\n",
    "Tukey's Honestly Significant Difference (Tukey HSD):\n",
    "\n",
    "When to Use: Tukey's HSD is a conservative post-hoc test suitable when you have performed a one-way ANOVA with equal sample sizes across groups and you want to compare all possible pairs of group means.\n",
    "Example: In a study comparing the effects of three different diets on weight loss, if the ANOVA indicates a significant difference, you can use Tukey's HSD to determine which pairs of diets are significantly different from each other.\n",
    "Bonferroni Correction:\n",
    "\n",
    "When to Use: Bonferroni correction is used when you want to control the familywise error rate (the probability of making at least one Type I error) in situations where multiple pairwise comparisons are made. It's more conservative but controls for inflated Type I error rates.\n",
    "Example: If you are conducting multiple pairwise comparisons after an ANOVA (e.g., comparing the effects of a treatment to multiple control groups), you might use the Bonferroni correction to protect against the increased risk of Type I errors.\n",
    "Dunnett's Test:\n",
    "\n",
    "When to Use: Dunnett's test is used when you have one control group and you want to compare it to multiple treatment groups. It's useful when you have a control group to which you want to compare other groups.\n",
    "Example: In a drug trial, you have one control group receiving a placebo, and several other groups receiving different doses of the drug. Dunnett's test helps you determine which drug doses are significantly different from the placebo.\n",
    "Scheffé's Test:\n",
    "\n",
    "When to Use: Scheffé's test is used when you have unequal sample sizes across groups and you want to make all possible pairwise comparisons while controlling for the overall Type I error rate.\n",
    "Example: In a study comparing the performance of students from different schools where the sample sizes for schools vary, Scheffé's test can be used to make pairwise comparisons while accounting for the sample size differences.\n",
    "Games-Howell Test:\n",
    "\n",
    "When to Use: The Games-Howell test is used when the assumption of equal variances across groups is violated (heteroscedasticity) and you want to make pairwise comparisons with unequal sample sizes and variances.\n",
    "Example: If you are comparing the effects of different teaching methods on test scores and the variances of test scores in the groups are unequal, you might use the Games-Howell test to compare groups.\n",
    "Holm-Bonferroni Method:\n",
    "\n",
    "When to Use: The Holm-Bonferroni method is a modification of the Bonferroni correction and is used when you have multiple pairwise comparisons, but you want a less conservative approach than Bonferroni. It ranks p-values and adjusts them accordingly.\n",
    "Example: When comparing the effects of multiple treatments on patient outcomes, you might use the Holm-Bonferroni method to control the overall Type I error rate while allowing for a less stringent correction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd64e11-ed44-4987-8465-566ff56e880b",
   "metadata": {},
   "source": [
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b546294-13ee-4bee-a73a-7f71c52c1d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 320.95652173913095\n",
      "P-value: 9.470518083409838e-32\n",
      "The one-way ANOVA is statistically significant.\n",
      "There is evidence of at least one significant difference among the diet groups.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data for each diet group (replace with your actual data)\n",
    "diet_A = np.array([2.5, 3.0, 2.8, 3.2, 2.9, 3.1, 2.7, 2.8, 2.9, 3.3, 2.8, 3.2, 2.6, 3.1, 3.0, 2.9, 3.0, 3.1, 2.7, 2.8])\n",
    "diet_B = np.array([2.0, 2.1, 2.2, 1.9, 2.3, 2.1, 2.2, 2.0, 2.1, 2.4, 2.2, 2.1, 2.0, 2.2, 2.3, 2.1, 2.0, 2.2, 2.3, 2.1])\n",
    "diet_C = np.array([3.5, 3.6, 3.3, 3.8, 3.4, 3.6, 3.3, 3.7, 3.5, 3.4, 3.7, 3.6, 3.8, 3.3, 3.5, 3.6, 3.4, 3.3, 3.7, 3.8])\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05  # Set the significance level\n",
    "print(f\"F-statistic: {f_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"The one-way ANOVA is statistically significant.\")\n",
    "    print(\"There is evidence of at least one significant difference among the diet groups.\")\n",
    "else:\n",
    "    print(\"The one-way ANOVA is not statistically significant.\")\n",
    "    print(\"There is no strong evidence of differences among the diet groups.\")\n",
    "\n",
    "# You can perform post hoc tests (e.g., Tukey's HSD) if the ANOVA is significant to identify specific group differences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30930a47-baeb-4fa9-8687-6d440ae4db02",
   "metadata": {},
   "source": [
    "Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "interaction effects between the software programs and employee experience level (novice vs.\n",
    "experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e6d79c6-03fc-4e15-9895-66da1bbc76f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Effect of Software - F-statistic: 2.11381360335568, p-value: 0.1427060620455933\n",
      "Main Effect of Experience - F-statistic: 0.7976521470238848, p-value: 0.38066469830684124\n",
      "Interaction Effect - F-statistic: 1.14085719952035, p-value: 0.3362719187555285\n",
      "There is no significant main effect of Software.\n",
      "There is no significant main effect of Experience.\n",
      "There is no significant interaction effect between Software and Experience.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "# Sample data (replace with your actual data)\n",
    "np.random.seed(0)  # For reproducibility\n",
    "n = 30\n",
    "software_programs = np.random.choice(['A', 'B', 'C'], n)\n",
    "experience_levels = np.random.choice(['Novice', 'Experienced'], n)\n",
    "task_completion_time = np.random.normal(10, 2, n)  # Mean 10, Std. Dev. 2\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({'Software': software_programs, 'Experience': experience_levels, 'Time': task_completion_time})\n",
    "\n",
    "# Perform two-way ANOVA\n",
    "formula = 'Time ~ C(Software) + C(Experience) + C(Software):C(Experience)'\n",
    "model = ols(formula, data=data).fit()\n",
    "anova_table = anova_lm(model, typ=2)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05  # Set the significance level\n",
    "\n",
    "# Main effect of Software\n",
    "f_statistic_software = anova_table['F']['C(Software)']\n",
    "p_value_software = anova_table['PR(>F)']['C(Software)']\n",
    "\n",
    "# Main effect of Experience\n",
    "f_statistic_experience = anova_table['F']['C(Experience)']\n",
    "p_value_experience = anova_table['PR(>F)']['C(Experience)']\n",
    "\n",
    "# Interaction effect\n",
    "f_statistic_interaction = anova_table['F']['C(Software):C(Experience)']\n",
    "p_value_interaction = anova_table['PR(>F)']['C(Software):C(Experience)']\n",
    "\n",
    "print(f\"Main Effect of Software - F-statistic: {f_statistic_software}, p-value: {p_value_software}\")\n",
    "print(f\"Main Effect of Experience - F-statistic: {f_statistic_experience}, p-value: {p_value_experience}\")\n",
    "print(f\"Interaction Effect - F-statistic: {f_statistic_interaction}, p-value: {p_value_interaction}\")\n",
    "\n",
    "if p_value_software < alpha:\n",
    "    print(\"There is a significant main effect of Software.\")\n",
    "else:\n",
    "    print(\"There is no significant main effect of Software.\")\n",
    "\n",
    "if p_value_experience < alpha:\n",
    "    print(\"There is a significant main effect of Experience.\")\n",
    "else:\n",
    "    print(\"There is no significant main effect of Experience.\")\n",
    "\n",
    "if p_value_interaction < alpha:\n",
    "    print(\"There is a significant interaction effect between Software and Experience.\")\n",
    "else:\n",
    "    print(\"There is no significant interaction effect between Software and Experience.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8253ec9e-4045-4b77-b230-6297e9657a48",
   "metadata": {},
   "source": [
    "Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e178779f-8f07-4493-8a54-e2df9eaebcdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-Sample T-Test - t-statistic: -4.131173276068804, p-value: 7.60404836914434e-05\n",
      "The two-sample t-test is statistically significant.\n",
      "There is evidence of a significant difference in test scores between the control and experimental groups.\n",
      "\n",
      "Post-Hoc Test (Tukey's HSD):\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "=========================================================\n",
      " group1    group2    meandiff p-adj  lower  upper  reject\n",
      "---------------------------------------------------------\n",
      "Control Experimental   4.1925 0.0001 2.1786 6.2064   True\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Sample data (replace with your actual data)\n",
    "np.random.seed(0)  # For reproducibility\n",
    "control_group_scores = np.random.normal(70, 5, 50)  # Control group with a mean of 70 and std. deviation of 5\n",
    "experimental_group_scores = np.random.normal(75, 5, 50)  # Experimental group with a mean of 75 and std. deviation of 5\n",
    "\n",
    "# Perform a two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_group_scores, experimental_group_scores)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05  # Set the significance level\n",
    "\n",
    "print(f\"Two-Sample T-Test - t-statistic: {t_statistic}, p-value: {p_value}\")\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"The two-sample t-test is statistically significant.\")\n",
    "    print(\"There is evidence of a significant difference in test scores between the control and experimental groups.\")\n",
    "else:\n",
    "    print(\"The two-sample t-test is not statistically significant.\")\n",
    "    print(\"There is no strong evidence of a difference in test scores between the groups.\")\n",
    "\n",
    "# If the t-test is significant, perform a post-hoc test (Tukey's HSD) to determine which group(s) differ significantly\n",
    "if p_value < alpha:\n",
    "    data = np.concatenate([control_group_scores, experimental_group_scores])\n",
    "    group_labels = ['Control'] * 50 + ['Experimental'] * 50\n",
    "    tukey_result = pairwise_tukeyhsd(data, group_labels, alpha=alpha)\n",
    "\n",
    "    print(\"\\nPost-Hoc Test (Tukey's HSD):\")\n",
    "    print(tukey_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd025a1-ec49-49af-9fc3-dff34456389e",
   "metadata": {},
   "source": [
    "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n",
    "\n",
    "significant differences in sales between the three stores. If the results are significant, follow up with a post-\n",
    "hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c08977c-c739-4eb5-8ea1-ad0185908d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Way ANOVA - F-statistic: 14.890001572904103, p-value: 2.7451020567943175e-06\n",
      "The one-way ANOVA is statistically significant.\n",
      "There is evidence of a significant difference in daily sales between the stores.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data for daily sales (replace with your actual data)\n",
    "store_A_sales = np.random.randint(1000, 1500, 30)  # Daily sales for Store A\n",
    "store_B_sales = np.random.randint(800, 1300, 30)   # Daily sales for Store B\n",
    "store_C_sales = np.random.randint(900, 1400, 30)   # Daily sales for Store C\n",
    "\n",
    "# Combine the sales data into one array\n",
    "all_sales_data = np.concatenate([store_A_sales, store_B_sales, store_C_sales])\n",
    "\n",
    "# Create a group labels array\n",
    "group_labels = ['Store A'] * 30 + ['Store B'] * 30 + ['Store C'] * 30\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(store_A_sales, store_B_sales, store_C_sales)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05  # Set the significance level\n",
    "\n",
    "print(f\"One-Way ANOVA - F-statistic: {f_statistic}, p-value: {p_value}\")\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"The one-way ANOVA is statistically significant.\")\n",
    "    print(\"There is evidence of a significant difference in daily sales between the stores.\")\n",
    "else:\n",
    "    print(\"The one-way ANOVA is not statistically significant.\")\n",
    "    print(\"There is no strong evidence of a difference in daily sales between the stores.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6562360b-4dc1-4780-8dd9-958d7da5dff1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
